# Phase 2 Testing Guide

## Overview

This guide provides comprehensive testing procedures for all Phase 2 (Intelligence) features. Follow these test cases to validate functionality, accuracy, and user experience.

---

## üß™ Test Environment Setup

### Frontend Testing
The frontend application (Next.js) includes a comprehensive test suite using Jest and React Testing Library.

#### Running Frontend Tests
```bash
cd frontend
npm install              # Ensure dependencies are installed
npm test                 # Run all tests
npm run test:coverage    # Run tests with coverage report
npm run test:watch       # Run tests in watch mode
```

#### Test Coverage Requirements
- **Backend Unit**: ‚â•90% lines/functions (enforced via `--cov-fail-under=90`)
- **Backend Integration**: ‚â•70% lines/functions (enforced via `--cov-fail-under=70`)
- **Frontend Global**: ‚â•85% lines/functions; branches ‚â•70% (enforced in `jest.config.ts`)

#### Key Testing Practices
- **Mocking**: Next.js hooks (`useRouter`, `usePathname`) and `fetch` are mocked globally or per test.
- **Async Handling**: Use `act()` and `waitFor()` for state updates. Use `jest.useFakeTimers()` for time-dependent logic.
- **Accessibility**: Prefer accessible queries (`getByRole`, `getByLabelText`).

---

### Backend Prerequisites
```bash
# 1. Ensure dependencies are installed
pip install -r requirements.txt

# 2. Set API key (at least one)
export OPENAI_API_KEY="your-key"

# 3. Run the modern app
./run_modern.sh
# or directly:
streamlit run app_modern.py
```

### Backend Testing
Use these commands to validate the backend quickly:
```bash
# Run unit/integration tests
python -m pytest

# Lint (imports, style) and auto-fix suggestions
python -m ruff check .

# Type checks
python -m mypy
```

#### CORS Verification
- Development: set ENVIRONMENT=development and ensure CORS_ALLOW_ORIGINS is unset. Expected: Allow-Origin: *
- Production: set ENVIRONMENT=production and set CORS_ALLOW_ORIGINS to a comma-separated list (e.g., https://example.com, https://app.local). Expected: only listed origins allowed.

#### Coverage Expectations
- Unit tests target ‚â•85% coverage across core modules.
- Critical modules (dependencies, lifecycle, auth) aim for ‚â•90% coverage.

### Initial Configuration
1. Open UI in browser: http://localhost:3000
2. Navigate to Search and run a sample query (e.g., "apartments in Krakow")
3. Navigate to Assistant and verify streaming responses render progressively

---

## üìã Test Suite Overview

| Test Area | Test Cases | Priority |
|-----------|------------|----------|
| Query Analyzer | 8 | High |
| Hybrid Agent Routing | 6 | High |
| Tool Integration | 4 | High |
| Result Reranking | 3 | Medium |
| UI Integration | 5 | Medium |
| Error Handling | 4 | Medium |

---

## 1Ô∏è‚É£ Query Analyzer Tests

### Test 1.1: Simple Retrieval Intent
**Query:** `"Show me apartments in Krakow"`

**Expected Analysis:**
- Intent: `SIMPLE_RETRIEVAL`
- Complexity: `SIMPLE`
- Tools: `[RAG_RETRIEVAL]`
- Extracted Filters: `{city: "Krakow"}`
- Should use agent: `False`

**Expected Processing:**
- Method: üìö RAG
- Response time: 1-3s
- Results: List of Krakow apartments

**Pass Criteria:**
- ‚úÖ Query classified correctly
- ‚úÖ RAG used (not agent)
- ‚úÖ Results relevant to Krakow
- ‚úÖ Fast response time

---

### Test 1.2: Filtered Search Intent
**Query:** `"Find 2-bedroom apartments under $1000 with parking"`

**Expected Analysis:**
- Intent: `FILTERED_SEARCH`
- Complexity: `MEDIUM`
- Tools: `[RAG_RETRIEVAL]`
- Extracted Filters: `{rooms: 2, max_price: 1000, has_parking: true}`
- Should use agent: `False`

**Expected Processing:**
- Method: üìö RAG
- Response time: 2-4s
- Results: Properties matching all filters
- Reranking applied: ‚ú®

**Pass Criteria:**
- ‚úÖ All filters extracted correctly
- ‚úÖ Results match filters (2-bed, <$1000, parking)
- ‚úÖ Reranking improves relevance
- ‚úÖ No false positives

---

### Test 1.3: Calculation Intent
**Query:** `"Calculate mortgage for $150,000 property with 20% down at 4.5% interest"`

**Expected Analysis:**
- Intent: `CALCULATION`
- Complexity: `COMPLEX`
- Tools: `[MORTGAGE_CALC]`
- Extracted Filters: None
- Should use agent: `True`

**Expected Processing:**
- Method: üõ†Ô∏è Agent + Tools
- Response time: 3-6s
- Output: Detailed mortgage breakdown

**Pass Criteria:**
- ‚úÖ Calculation intent detected
- ‚úÖ Mortgage calculator tool invoked
- ‚úÖ Correct calculations:
  - Down payment: $30,000
  - Loan amount: $120,000
  - Monthly payment: ~$608
  - Total interest: ~$98,880
- ‚úÖ Clear formatting

---

### Test 1.4: Comparison Intent
**Query:** `"Compare apartments in Warsaw vs Krakow"`

**Expected Analysis:**
- Intent: `COMPARISON`
- Complexity: `COMPLEX`
- Tools: `[RAG_RETRIEVAL, COMPARATOR]`
- Extracted Filters: `{city: "Warsaw"}, {city: "Krakow"}`
- Should use agent: `True`

**Expected Processing:**
- Method: üîÄ Hybrid
- Response time: 6-12s
- Output: Side-by-side comparison

**Pass Criteria:**
- ‚úÖ Comparison intent detected
- ‚úÖ Both cities included
- ‚úÖ Statistical comparison provided
- ‚úÖ Clear differences highlighted

---

### Test 1.5: Analysis Intent
**Query:** `"What's the average price per square meter in Krakow?"`

**Expected Analysis:**
- Intent: `ANALYSIS`
- Complexity: `COMPLEX`
- Tools: `[RAG_RETRIEVAL, PYTHON_CODE]`
- Should use agent: `True`

**Expected Processing:**
- Method: üîÄ Hybrid or üõ†Ô∏è Agent
- Response time: 5-10s
- Output: Statistical analysis

**Pass Criteria:**
- ‚úÖ Analysis intent detected
- ‚úÖ Calculation performed
- ‚úÖ Average provided with context
- ‚úÖ Sample size mentioned

---

### Test 1.6: Recommendation Intent
**Query:** `"What's the best value apartment for $1000?"`

**Expected Analysis:**
- Intent: `RECOMMENDATION`
- Complexity: `COMPLEX`
- Tools: `[RAG_RETRIEVAL]`
- Should use agent: Depends

**Expected Processing:**
- Method: üìö RAG or üîÄ Hybrid
- Response time: 3-8s
- Output: Top recommendations with reasoning

**Pass Criteria:**
- ‚úÖ Recommendation intent detected
- ‚úÖ Value-based ranking
- ‚úÖ Explanation provided
- ‚úÖ Multiple options shown

---

### Test 1.7: Conversation Intent
**Query:** `"Tell me more about the last property"` (requires previous context)

**Expected Analysis:**
- Intent: `CONVERSATION`
- Complexity: `SIMPLE` or `MEDIUM`
- Tools: `[RAG_RETRIEVAL]`

**Expected Processing:**
- Method: üìö RAG
- Response time: 2-4s
- Output: Details about previously mentioned property

**Pass Criteria:**
- ‚úÖ Conversation intent detected
- ‚úÖ Context maintained
- ‚úÖ Relevant details provided
- ‚úÖ References previous query

---

### Test 1.8: Multi-Filter Complex Query
**Query:** `"Show me 2-3 bedroom apartments in Krakow between $800-$1200 with parking and garden near schools"`

**Expected Analysis:**
- Intent: `FILTERED_SEARCH`
- Complexity: `MEDIUM` or `COMPLEX`
- Tools: `[RAG_RETRIEVAL]`
- Extracted Filters:
  ```
  {
    rooms: [2, 3],
    city: "Krakow",
    min_price: 800,
    max_price: 1200,
    has_parking: true,
    has_garden: true
  }
  ```

**Expected Processing:**
- Method: üìö RAG
- Response time: 3-5s
- Reranking: ‚ú® Applied

**Pass Criteria:**
- ‚úÖ All filters extracted
- ‚úÖ Results match all criteria
- ‚úÖ Proximity to schools mentioned
- ‚úÖ Results prioritized well

---

## 2Ô∏è‚É£ Hybrid Agent Routing Tests

### Test 2.1: RAG-Only Path (Simple Query)
**Setup:** Enable hybrid agent

**Query:** `"Show me apartments in Warsaw"`

**Expected:**
- Routing: RAG-only
- No tools invoked
- Fast response (~2s)
- Badge: üìö RAG

**Validation:**
```python
# Check in verbose mode or logs
assert routing_decision == "rag_only"
assert no_tools_used == True
assert response_time < 3s
```

---

### Test 2.2: Agent-Only Path (Pure Calculation)
**Query:** `"Calculate mortgage for $200,000 with 15% down at 5% for 25 years"`

**Expected:**
- Routing: Agent + Tools
- Mortgage calculator tool invoked
- No RAG retrieval needed
- Badge: üõ†Ô∏è Agent + Tools

**Validation:**
- ‚úÖ Tool output visible
- ‚úÖ Accurate calculations
- ‚úÖ No property retrieval
- ‚úÖ Clear breakdown

---

### Test 2.3: Hybrid Path (Query + Analysis)
**Query:** `"Compare the average prices of 2-bedroom apartments in all cities"`

**Expected:**
- Routing: Hybrid
- RAG retrieves properties
- Agent performs analysis
- Badge: üîÄ Hybrid

**Validation:**
- ‚úÖ Properties retrieved first
- ‚úÖ Analysis performed second
- ‚úÖ Both steps visible
- ‚úÖ Comprehensive answer

---

### Test 2.4: Toggle Agent Off/On
**Test Steps:**
1. Disable "Use Hybrid Agent"
2. Query: `"Calculate mortgage for $180,000"`
3. **Expected:** Simple RAG response (no calculation)
4. Enable "Use Hybrid Agent"
5. Same query
6. **Expected:** Proper mortgage calculation

**Pass Criteria:**
- ‚úÖ Without agent: Generic/incomplete response
- ‚úÖ With agent: Accurate calculation
- ‚úÖ Clear difference in quality

---

### Test 2.5: Error Recovery
**Query:** `"Calculate mortgage for invalid property"` (intentionally vague)

**Expected:**
- Agent attempts to use tool
- Tool returns error or asks for clarification
- Fallback to RAG or explanation
- No crash

**Pass Criteria:**
- ‚úÖ Graceful error handling
- ‚úÖ User-friendly message
- ‚úÖ No stack trace shown
- ‚úÖ Suggests correct format

---

### Test 2.6: Context Injection
**Query:** `"Compare these properties"` (after viewing several)

**Expected:**
- Agent retrieves recent properties from context
- Performs comparison on actual data
- Uses comparator tool

**Pass Criteria:**
- ‚úÖ Context understood
- ‚úÖ Correct properties compared
- ‚úÖ Detailed comparison
- ‚úÖ No hallucination

---

## 3Ô∏è‚É£ Tool Integration Tests

### Test 3.1: Mortgage Calculator Accuracy
**Test Queries:**

1. `"Calculate mortgage for $100,000, 20% down, 4% rate, 30 years"`
   - Expected monthly: $382

2. `"Calculate mortgage for $250,000, 10% down, 6% rate, 15 years"`
   - Expected monthly: $1,899

3. `"Calculate mortgage for $180,000, 25% down, 3.5% rate, 20 years"`
   - Expected monthly: $781

**Pass Criteria:**
- ‚úÖ All calculations within ¬±$5 of expected
- ‚úÖ Down payment calculated correctly
- ‚úÖ Total interest calculated correctly
- ‚úÖ Formula: M = P[r(1+r)^n]/[(1+r)^n-1]

---

### Test 3.2: Property Comparator
**Query:** `"Compare a 2-bed apartment at $900 vs a 3-bed at $1200"`

**Expected Output:**
- Side-by-side comparison
- Price per room analysis
- Feature comparison
- Recommendation

**Pass Criteria:**
- ‚úÖ Both properties analyzed
- ‚úÖ Pros/cons listed
- ‚úÖ Value assessment
- ‚úÖ Clear winner or trade-offs

---

### Test 3.3: Price Analyzer
**Query:** `"Analyze the price distribution in Krakow"`

**Expected Output:**
- Average, median, min, max
- Price ranges
- Statistical breakdown
- Sample size

**Pass Criteria:**
- ‚úÖ Statistics calculated
- ‚úÖ Distribution described
- ‚úÖ Sample size mentioned
- ‚úÖ Insights provided

---

### Test 3.4: Multiple Tool Chain
**Query:** `"Find best value 2-bed under $1000 and calculate mortgage"`

**Expected:**
- RAG tool: Retrieve properties
- Comparator tool: Find best value
- Mortgage calc tool: Calculate for selected property
- Chained execution

**Pass Criteria:**
- ‚úÖ All tools used in sequence
- ‚úÖ Results flow logically
- ‚úÖ Final answer comprehensive
- ‚úÖ No tool errors

---

## 4Ô∏è‚É£ Result Reranking Tests

### Test 4.1: Exact Match Boosting
**Setup:** Query with specific keywords

**Query:** `"Affordable studio with garden"`

**Without Reranking:**
- Observe initial order of results

**With Reranking:**
- Properties with "garden" should rank higher
- "Affordable" properties boosted
- Exact keyword matches prioritized

**Pass Criteria:**
- ‚úÖ Reranked order different from initial
- ‚úÖ More relevant results at top
- ‚úÖ Keyword matches prioritized
- ‚úÖ ‚ú® Badge displayed

---

### Test 4.2: Metadata Alignment
**Query:** `"2-bedroom with parking under $1000"`

**With Reranking:**
- Properties matching all criteria rank highest
- Properties matching 2/3 criteria next
- Properties matching 1/3 criteria lowest

**Pass Criteria:**
- ‚úÖ Perfect matches at top
- ‚úÖ Partial matches ordered by relevance
- ‚úÖ Non-matches filtered or ranked low
- ‚úÖ Visible quality improvement

---

### Test 4.3: Diversity Penalty
**Query:** `"Show me apartments"`

**With Reranking:**
- Results should show variety of cities
- Results should show variety of price ranges
- Not all results from same neighborhood

**Pass Criteria:**
- ‚úÖ Multiple cities represented
- ‚úÖ Price range diversity
- ‚úÖ Not clustering on single feature
- ‚úÖ Better user experience

---

## 5Ô∏è‚É£ UI Integration Tests

### Test 5.1: Query Analysis Display
**Steps:**
1. Enable "Show Query Analysis"
2. Enter query: `"Find 2-bed with parking under $1000"`
3. Observe analysis display

**Expected Display:**
```
üîç Query Analysis
Intent: filtered_search
Complexity: medium
Tools needed: [rag_retrieval]
Extracted filters: {rooms: 2, has_parking: true, max_price: 1000}
Should use agent: False
```

**Pass Criteria:**
- ‚úÖ Analysis appears before results
- ‚úÖ Expandable section
- ‚úÖ All fields populated correctly
- ‚úÖ Easy to read format

---

### Test 5.2: Processing Badges
**Test Different Query Types:**

1. Simple: Should show üìö RAG
2. Calculation: Should show üõ†Ô∏è Agent + Tools
3. Analysis: Should show üîÄ Hybrid
4. With reranking: Should show ‚ú® Reranked

**Pass Criteria:**
- ‚úÖ Correct badge for each type
- ‚úÖ Badge visible and clear
- ‚úÖ Consistent placement
- ‚úÖ Informative for user

---

### Test 5.3: Model Switching
**Steps:**
1. Start with GPT-4o-mini
2. Run query: `"Show me apartments"`
3. Switch to Claude 3.5 Haiku
4. Run same query
5. Compare results

**Pass Criteria:**
- ‚úÖ No errors during switch
- ‚úÖ Agent reinitializes correctly
- ‚úÖ Both provide valid results
- ‚úÖ Quality comparable

---

### Test 5.4: Feature Toggle Persistence
**Steps:**
1. Enable all Phase 2 features
2. Refresh page
3. Check if settings persist

**Expected:**
- Session state maintained
- Settings preserved
- No reset to defaults

**Pass Criteria:**
- ‚úÖ Hybrid agent still enabled
- ‚úÖ Query analysis still enabled
- ‚úÖ Reranking still enabled
- ‚úÖ Seamless experience

---

### Test 5.5: Source Attribution
**Query:** `"Show me apartments in Krakow"`

**Expected:**
- Source documents displayed
- Expandable section
- Metadata visible
- Content preview

**Pass Criteria:**
- ‚úÖ Sources section present
- ‚úÖ Click to expand works
- ‚úÖ Metadata shows city, price, etc.
- ‚úÖ Content relevant to query

---

### Geographic Visualizations

- Price Heatmap
  - Unit tests: tests/unit/test_geo_viz_heatmap.py
  - Validates Folium map creation for empty and populated collections
  - Run: python -m pytest tests/unit/test_geo_viz_heatmap.py -q
  - Performance: includes large dataset test with 5k points

- City Overview
  - Unit tests: tests/unit/test_geo_viz_city_overview.py
  - Validates Folium map creation aggregating city statistics
  - Run: python -m pytest tests/unit/test_geo_viz_city_overview.py -q
  - Performance: includes large dataset test with 5k properties

#### UI Controls & Accessibility
- Mode switching within unified visualization section (Heatmap vs City Overview)
- Toggle states:
  - Jitter: enabled for Heatmap, disabled for City Overview
  - Clustering: disabled (not applicable in these modes)
  - Heatmap Radius/Blur: sliders active in Heatmap mode
  - City Overview Aggregates: checkbox controls popup statistics
- Accessibility:
  - Verify keyboard navigation for radio and checkbox controls
  - Check screen reader labels and help text
  - Ensure visual feedback during transitions (spinner)
  - Confirm screen reader announces mode changes via live region (‚ÄúVisualization mode changed‚Ä¶‚Äù)

---

## 6Ô∏è‚É£ Error Handling Tests

### Test 6.1: Invalid API Key
**Setup:** Use invalid or expired API key

**Expected:**
- Clear error message
- No cryptic stack trace
- Guidance on fixing
- App doesn't crash

**Pass Criteria:**
- ‚úÖ User-friendly error
- ‚úÖ Suggests checking API key
- ‚úÖ Can continue with different provider
- ‚úÖ Graceful degradation

---

### Test 6.2: No Data Loaded
**Steps:**
1. Start app without loading data
2. Try to query

**Expected:**
- Warning message
- Prompt to load data
- No crash
- Clear instructions

**Pass Criteria:**
- ‚úÖ Helpful message displayed
- ‚úÖ Points to sidebar
- ‚úÖ Doesn't attempt search
- ‚úÖ User knows what to do

---

### Test 6.3: Malformed Query
**Query:** `"jfkdlsjflkdsjf"` (random characters)

**Expected:**
- Attempts classification
- Returns generic response or asks for clarification
- No crash
- Helpful feedback

**Pass Criteria:**
- ‚úÖ Handles gracefully
- ‚úÖ Doesn't error out
- ‚úÖ Provides feedback
- ‚úÖ Can continue chatting

---

### Test 6.4: Tool Failure Recovery
**Setup:** Simulate tool failure (e.g., mortgage calc with invalid input)

**Expected:**
- Tool error caught
- Fallback to RAG or explanation
- User informed
- Can retry

**Pass Criteria:**
- ‚úÖ No app crash
- ‚úÖ Error explained
- ‚úÖ Alternative provided
- ‚úÖ Recoverable state

---

## üéØ Performance Tests

### Test P.1: Response Time Benchmarks
Run each query type 5 times and measure:

| Query Type | Target Time | Acceptable Range |
|------------|-------------|------------------|
| Simple RAG | 2s | 1-3s |
| Filtered + Rerank | 3s | 2-4s |
| Agent + Tool | 5s | 3-7s |
| Hybrid Analysis | 8s | 5-12s |

**Pass Criteria:**
- ‚úÖ 80% of queries within target
- ‚úÖ 95% within acceptable range
- ‚úÖ No timeouts
- ‚úÖ Consistent performance

---

### Test P.2: Concurrent Queries
**Setup:** Open multiple browser tabs

**Steps:**
1. Submit query in tab 1
2. Immediately submit query in tab 2
3. Check if both complete

**Pass Criteria:**
- ‚úÖ Both queries complete
- ‚úÖ No interference
- ‚úÖ Correct results in each tab
- ‚úÖ Session isolation

---

### Test P.3: Large Result Sets
**Query:** `"Show me all apartments"` (retrieves many results)

**Expected:**
- Handles large result sets
- UI remains responsive
- Results paginated or limited
- No browser freeze

**Pass Criteria:**
- ‚úÖ Returns promptly
- ‚úÖ UI stays responsive
- ‚úÖ Results manageable
- ‚úÖ No performance degradation

---

## üìä Test Results Template

```markdown
## Test Session: [Date]

### Configuration
- App Version: V3 - Phase 2
- Model: [Provider/Model]
- Dataset: [Sample/Custom]
- Features Enabled: [Hybrid Agent, Query Analysis, Reranking]

### Results Summary
- Total Tests: X
- Passed: Y
- Failed: Z
- Pass Rate: Y/X%

### Test Details

#### Test 1.1: Simple Retrieval
- Status: ‚úÖ PASS / ‚ùå FAIL
- Notes: [Any observations]

[Repeat for all tests]

### Issues Found
1. [Issue description]
   - Severity: High/Medium/Low
   - Steps to reproduce
   - Expected vs Actual

### Recommendations
- [Improvements needed]
- [Edge cases to address]
- [Performance optimizations]
```

---

## üöÄ Running the Complete Test Suite

### Quick Test (15 minutes)
Run these essential tests:
- 1.1, 1.2, 1.3 (Query Analyzer)
- 2.1, 2.2 (Agent Routing)
- 3.1 (Mortgage Calculator)
- 4.1 (Reranking)
- 5.1, 5.2 (UI)

### Full Test (60 minutes)
Run all tests in order, document results

### Regression Test
Run after any code changes to ensure nothing broke

---

## üìã Acceptance Criteria

**Phase 2 is considered fully validated if:**

‚úÖ Query Analyzer: 90%+ accuracy on intent classification
‚úÖ Agent Routing: Correct routing in 95%+ of cases
‚úÖ Tools: All tools function correctly with <5% error rate
‚úÖ Reranking: Measurable improvement in top-3 relevance
‚úÖ UI: All features accessible and working
‚úÖ Performance: 90%+ of queries within target times
‚úÖ Errors: All errors handled gracefully
‚úÖ User Experience: Smooth, intuitive interaction

---

## üêõ Bug Reporting Template

```markdown
**Title:** [Brief description]

**Test Case:** [Which test revealed this]

**Steps to Reproduce:**
1. [Step 1]
2. [Step 2]
3. [Step 3]

**Expected Behavior:**
[What should happen]

**Actual Behavior:**
[What actually happened]

**Environment:**
- App Version: V3 Phase 2
- Model: [Provider/Model]
- Browser: [Browser/Version]
- OS: [Operating System]

**Screenshots/Logs:**
[Attach any relevant evidence]

**Severity:**
- [ ] Critical (blocks testing)
- [ ] High (major feature broken)
- [ ] Medium (feature partially broken)
- [ ] Low (minor issue)

**Priority:**
- [ ] P0 (fix immediately)
- [ ] P1 (fix before release)
- [ ] P2 (fix in next iteration)
- [ ] P3 (nice to have)
```

---

## üéì Testing Best Practices

1. **Test in Order**: Run tests sequentially to build confidence
2. **Document Everything**: Record observations, even for passing tests
3. **Test Edge Cases**: Try unusual inputs and scenarios
4. **Compare Models**: Test with different AI models
5. **Check Logs**: Review verbose output for issues
6. **User Perspective**: Test as an end user would interact
7. **Repeat Critical Tests**: Run important tests multiple times
8. **Test Combinations**: Try feature combinations
9. **Measure Performance**: Time responses systematically
10. **Report Issues**: Document bugs immediately with details

---

**Happy Testing! üß™**
### Playwright E2E Setup
```bash
# Install Playwright browsers (required for MCP/CLI)
npx playwright install
npx playwright install chromium

# Run e2e tests
npx playwright test -c playwright.config.ts --reporter=list
```
Note: Playwright is used for CI and local debugging only. The application does not include any MCP Playwright integrations or test‚Äëspecific DOM markers.
